{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment3_2.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2i5qBWkKTH"
      },
      "source": [
        "# POS tagging using HMM\n",
        "\n",
        "In this assignment, part-of-speech tagging has been performed using Hidden Markov model. The model is implemented using own approach from scratch and using NLTK package preexisting model.\n",
        "\n",
        "1.   Accuracy using own approach - 87.87%\n",
        "2.   Accuracy with NLTK HMM model - 92.05%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCte7YT0nTLG"
      },
      "source": [
        "**Please find the [flowchart](https://drive.google.com/file/d/1j1gpVV2PryZaeShIY3-O9ORUo6GrKPls/view?usp=sharing) of this approach** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-vDBqnfkLwb"
      },
      "source": [
        "**Importing all the required packages and libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5hRtBHZ5f48",
        "outputId": "48c52197-2011-400a-c8eb-6e99e4a875c1"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from nltk.corpus import brown\n",
        "import random\n",
        "import statistics\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "devbYJoTka9W"
      },
      "source": [
        "# Obtaining the dataset in required formats\n",
        "\n",
        "*   'brown_news_tagged' contains (word,tag) pairs of news category data with universal tagset\n",
        "*   'words' contains only the words of brown_news_tagged\n",
        "*   'tags' and 'tags_list' contains only the tags of brown_news_tagged (with repetation)\n",
        "*   'unique_tags' contains unique tags of the entire dataset\n",
        "*   'vocab' contains unique words of the dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhXtRpG9Z7o"
      },
      "source": [
        "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
        "words = brown.words(categories='news')\n",
        "tags = []\n",
        "for i in range(len(brown_news_tagged)):\n",
        "  tags.append(brown_news_tagged[i][1])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L17JgMyW8n3",
        "outputId": "57e1ddb7-14d1-4c57-b9b4-107aea1aae01"
      },
      "source": [
        "print(brown_news_tagged[:5])\n",
        "print(words[:5])\n",
        "print(tags[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN')]\n",
            "['The', 'Fulton', 'County', 'Grand', 'Jury']\n",
            "['DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaXoO2jXBMoi",
        "outputId": "89217b0f-ee67-490f-8a8c-3d42159c7598"
      },
      "source": [
        "print(len(words))\n",
        "print(len(tags))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100554\n",
            "100554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzsPqZw3XIX3"
      },
      "source": [
        "unique_tags = list({tag for word,tag in train_set})\n",
        "tags_list = []\n",
        "for i in range(len(train_set)):\n",
        "  tags_list.append(train_set[i][1])\n",
        "vocab = {word for word,tag in train_set}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WhZC6H3lru8"
      },
      "source": [
        "# Obtaining the train set and test set using train_test_spit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crto6ZgxQTMO"
      },
      "source": [
        "# split data into training and validation set in the ratio 80:20\n",
        "train_set,test_set =train_test_split(brown_news_tagged,train_size=0.80,test_size=0.20)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq45S4lhLVPb",
        "outputId": "79d58ffd-aa6a-4784-e397-1105e5a47922"
      },
      "source": [
        "train_set[0:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DET'), ('.', '.'), ('the', 'DET'), ('we', 'PRON'), ('that', 'DET')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deLcdKMblzOG"
      },
      "source": [
        "# Function for calculating Transition probability of consecutive tag pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcP9Hw_TXhSI"
      },
      "source": [
        "# Calculating occurance of tag t2 after tag t1. Later to be used for transition probability\n",
        "\n",
        "def t2_given_t1(t2, t1, tags_list):\n",
        "  \n",
        "  t1_count = 0\n",
        "  t2_after_t1 = 0\n",
        "  for i in range(len(tags_list)-1):\n",
        "    # Counting the number of times tag t1 occurs\n",
        "    if tags_list[i] == t1:\n",
        "      t1_count += 1\n",
        "      # Counting the number of times tag t2 occurs after tag t1\n",
        "      if tags_list[i+1] == t2:\n",
        "        t2_after_t1 += 1\n",
        "\n",
        "  return t2_after_t1/t1_count"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hil4uW1l9yD"
      },
      "source": [
        "# Construction tags matrix using transition probability function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkJyP0KgXlxh"
      },
      "source": [
        "# Creating n x n transition matrix of unique_tags\n",
        " \n",
        "tags_matrix = np.zeros((len(unique_tags), len(unique_tags)), dtype='float32')\n",
        "i = 0\n",
        "for t1 in unique_tags:\n",
        "  j = 0\n",
        "  for t2 in unique_tags: \n",
        "    # Matrix(i, j) represents P(jth tag after the ith tag)\n",
        "    tags_matrix[i, j] = t2_given_t1(t2, t1, tags_list)\n",
        "    j += 1\n",
        "  i += 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "XsVjmSidXyUS",
        "outputId": "2d409f98-07ee-4d72-e1fa-c6dc6e5a3663"
      },
      "source": [
        "tags_df = pd.DataFrame(tags_matrix, columns = list(unique_tags), index=list(unique_tags))\n",
        "display(tags_df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADP</th>\n",
              "      <th>CONJ</th>\n",
              "      <th>.</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>NOUN</th>\n",
              "      <th>PRT</th>\n",
              "      <th>NUM</th>\n",
              "      <th>ADV</th>\n",
              "      <th>PRON</th>\n",
              "      <th>VERB</th>\n",
              "      <th>X</th>\n",
              "      <th>DET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ADP</th>\n",
              "      <td>0.123169</td>\n",
              "      <td>0.028377</td>\n",
              "      <td>0.121033</td>\n",
              "      <td>0.068450</td>\n",
              "      <td>0.303499</td>\n",
              "      <td>0.020545</td>\n",
              "      <td>0.021461</td>\n",
              "      <td>0.032547</td>\n",
              "      <td>0.025834</td>\n",
              "      <td>0.140460</td>\n",
              "      <td>0.001017</td>\n",
              "      <td>0.113609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONJ</th>\n",
              "      <td>0.113407</td>\n",
              "      <td>0.027548</td>\n",
              "      <td>0.129017</td>\n",
              "      <td>0.064279</td>\n",
              "      <td>0.314509</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.022039</td>\n",
              "      <td>0.028926</td>\n",
              "      <td>0.026630</td>\n",
              "      <td>0.142792</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>0.119949</td>\n",
              "      <td>0.025253</td>\n",
              "      <td>0.118792</td>\n",
              "      <td>0.071864</td>\n",
              "      <td>0.304924</td>\n",
              "      <td>0.023148</td>\n",
              "      <td>0.022096</td>\n",
              "      <td>0.034091</td>\n",
              "      <td>0.023043</td>\n",
              "      <td>0.143624</td>\n",
              "      <td>0.001052</td>\n",
              "      <td>0.112163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADJ</th>\n",
              "      <td>0.122940</td>\n",
              "      <td>0.028143</td>\n",
              "      <td>0.110720</td>\n",
              "      <td>0.069802</td>\n",
              "      <td>0.299944</td>\n",
              "      <td>0.026847</td>\n",
              "      <td>0.020737</td>\n",
              "      <td>0.032772</td>\n",
              "      <td>0.027217</td>\n",
              "      <td>0.147010</td>\n",
              "      <td>0.000926</td>\n",
              "      <td>0.112942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOUN</th>\n",
              "      <td>0.123254</td>\n",
              "      <td>0.027005</td>\n",
              "      <td>0.116085</td>\n",
              "      <td>0.064519</td>\n",
              "      <td>0.304468</td>\n",
              "      <td>0.023258</td>\n",
              "      <td>0.021425</td>\n",
              "      <td>0.034703</td>\n",
              "      <td>0.026557</td>\n",
              "      <td>0.143905</td>\n",
              "      <td>0.001018</td>\n",
              "      <td>0.113804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRT</th>\n",
              "      <td>0.129834</td>\n",
              "      <td>0.023204</td>\n",
              "      <td>0.116022</td>\n",
              "      <td>0.066298</td>\n",
              "      <td>0.285635</td>\n",
              "      <td>0.023757</td>\n",
              "      <td>0.020994</td>\n",
              "      <td>0.034254</td>\n",
              "      <td>0.027072</td>\n",
              "      <td>0.152486</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>0.119890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM</th>\n",
              "      <td>0.114620</td>\n",
              "      <td>0.023392</td>\n",
              "      <td>0.125146</td>\n",
              "      <td>0.070175</td>\n",
              "      <td>0.308772</td>\n",
              "      <td>0.019298</td>\n",
              "      <td>0.022807</td>\n",
              "      <td>0.036257</td>\n",
              "      <td>0.023977</td>\n",
              "      <td>0.140936</td>\n",
              "      <td>0.001170</td>\n",
              "      <td>0.113450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADV</th>\n",
              "      <td>0.124436</td>\n",
              "      <td>0.030827</td>\n",
              "      <td>0.129323</td>\n",
              "      <td>0.073308</td>\n",
              "      <td>0.304511</td>\n",
              "      <td>0.018421</td>\n",
              "      <td>0.020301</td>\n",
              "      <td>0.030075</td>\n",
              "      <td>0.023684</td>\n",
              "      <td>0.128195</td>\n",
              "      <td>0.000752</td>\n",
              "      <td>0.116165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRON</th>\n",
              "      <td>0.121987</td>\n",
              "      <td>0.029021</td>\n",
              "      <td>0.113133</td>\n",
              "      <td>0.067388</td>\n",
              "      <td>0.311363</td>\n",
              "      <td>0.023119</td>\n",
              "      <td>0.029021</td>\n",
              "      <td>0.035908</td>\n",
              "      <td>0.027054</td>\n",
              "      <td>0.131825</td>\n",
              "      <td>0.001968</td>\n",
              "      <td>0.108214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VERB</th>\n",
              "      <td>0.119650</td>\n",
              "      <td>0.025732</td>\n",
              "      <td>0.114365</td>\n",
              "      <td>0.066453</td>\n",
              "      <td>0.312424</td>\n",
              "      <td>0.022267</td>\n",
              "      <td>0.020360</td>\n",
              "      <td>0.029284</td>\n",
              "      <td>0.024086</td>\n",
              "      <td>0.148501</td>\n",
              "      <td>0.000866</td>\n",
              "      <td>0.116011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.053333</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.346667</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.026667</td>\n",
              "      <td>0.026667</td>\n",
              "      <td>0.026667</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DET</th>\n",
              "      <td>0.125847</td>\n",
              "      <td>0.028428</td>\n",
              "      <td>0.123770</td>\n",
              "      <td>0.065821</td>\n",
              "      <td>0.302755</td>\n",
              "      <td>0.021430</td>\n",
              "      <td>0.019243</td>\n",
              "      <td>0.033567</td>\n",
              "      <td>0.023508</td>\n",
              "      <td>0.142795</td>\n",
              "      <td>0.000656</td>\n",
              "      <td>0.112180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ADP      CONJ         .  ...      VERB         X       DET\n",
              "ADP   0.123169  0.028377  0.121033  ...  0.140460  0.001017  0.113609\n",
              "CONJ  0.113407  0.027548  0.129017  ...  0.142792  0.000000  0.110652\n",
              ".     0.119949  0.025253  0.118792  ...  0.143624  0.001052  0.112163\n",
              "ADJ   0.122940  0.028143  0.110720  ...  0.147010  0.000926  0.112942\n",
              "NOUN  0.123254  0.027005  0.116085  ...  0.143905  0.001018  0.113804\n",
              "PRT   0.129834  0.023204  0.116022  ...  0.152486  0.000552  0.119890\n",
              "NUM   0.114620  0.023392  0.125146  ...  0.140936  0.001170  0.113450\n",
              "ADV   0.124436  0.030827  0.129323  ...  0.128195  0.000752  0.116165\n",
              "PRON  0.121987  0.029021  0.113133  ...  0.131825  0.001968  0.108214\n",
              "VERB  0.119650  0.025732  0.114365  ...  0.148501  0.000866  0.116011\n",
              "X     0.040000  0.053333  0.080000  ...  0.160000  0.000000  0.160000\n",
              "DET   0.125847  0.028428  0.123770  ...  0.142795  0.000656  0.112180\n",
              "\n",
              "[12 rows x 12 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJivBoUmD4T"
      },
      "source": [
        "# Function for calculating Emission probability of word tag pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJSAprozXazI"
      },
      "source": [
        "# Computing Emission Probability\n",
        "\n",
        "def word_given_tag(word, tag, train_set):\n",
        " \n",
        "  spec_t_count = 0\n",
        "  spec_w_count = 0\n",
        "  for i in range(len(train_set)):\n",
        "    # Calculating the total number of times the passed tag occured\n",
        "    if train_set[i][1] == tag:\n",
        "      spec_t_count += 1\n",
        "      # Calculating the total number of times the passed word occurred as the passed tag\n",
        "      if train_set[i][0] == word:\n",
        "        spec_w_count += 1\n",
        "  return spec_w_count/spec_t_count"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E5mEQufmJAt"
      },
      "source": [
        "# Viterbi function for obtaining most appropriate word tag pair\n",
        "Viterbi function basically finds the final probability - emission * transmission for every word-tag pair and finds the maximum probability out of this pool. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhzmzqb_YjBp"
      },
      "source": [
        "def viterbi(words, unique_tags, train_set):\n",
        "\n",
        "  pred = []\n",
        "  for i in range(len(words)):\n",
        "    # Initializing list of probability list for a given pair\n",
        "    p = [] \n",
        "    for j in range(len(unique_tags)):\n",
        "      # transition probability for first word and first tag can't be calculated\n",
        "      if i == 0: transition = tags_df.loc['.', unique_tags[j]]\n",
        "      # transition probability calculation based on last chosen tag\n",
        "      else: transition = tags_df.loc[pred[-1], unique_tags[j]]\n",
        "            \n",
        "      # Computing emission and final probabilities\n",
        "      emission = word_given_tag(words[i], unique_tags[j], train_set)\n",
        "      pred_probability = transition * emission    \n",
        "      p.append(pred_probability)\n",
        "        \n",
        "    # Fetting the tag for the pair with maximum probability\n",
        "    pred_max = unique_tags[p.index(max(p))] \n",
        "    pred.append(pred_max)\n",
        "  return list(zip(words, pred))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkTT-_FKmg9s"
      },
      "source": [
        "# Selecting 50 random word tag pairs out of test set for testing\n",
        "After obtaining 50 such pairs, we obtain tagless words and measure the accuracy of out predicted tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fK88qV3YlUg"
      },
      "source": [
        "# Choose random 10 numbers for testing\n",
        "random_list = [random.randint(1,len(test_set)) for x in range(50)]\n",
        "test_run = []\n",
        "for i in random_list:\n",
        "  test_run.append(test_set[i])\n",
        "# list of 10 pairs on which we test the model\n",
        "test_run = [test_set[i] for i in random_list]\n",
        "\n",
        "test_run_base = []\n",
        "for i in range(len(test_run)):\n",
        "  test_run_base.append(test_run[i][0])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW-3YuWwYxvQ",
        "outputId": "7ca8d4f4-f152-40d1-da9e-14c6b3499e80"
      },
      "source": [
        "pred_sub = viterbi(test_run_base, unique_tags, train_set) \n",
        "# accuracy\n",
        "res_sub = []\n",
        "for i, j in zip(pred_sub, test_run):\n",
        "  if i == j: res_sub.append(i) \n",
        "accuracy = len(res_sub)/len(pred_sub)\n",
        "print('Accuracy of own approach on 50 randomly chosen words: ',accuracy*100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of own approach on 50 randomly chosen words:  94.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kuvH3xdmu5M"
      },
      "source": [
        "# Testing our approach on entire test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38hSSEvnmy6T"
      },
      "source": [
        "**Obtaining tagless words for experimentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCuVq3MwnNm2"
      },
      "source": [
        "test_untagged = []\n",
        "for i in range(len(test_set)):\n",
        "  test_untagged.append(test_set[i][0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHgt4-zPm34D"
      },
      "source": [
        "**Obtaining tags for untagged test set in the batches of 2000**\n",
        "Here, experimentation was done with different batch sizes and following results were obtained.\n",
        "*   Batch size 500 - 87.49\n",
        "*   Batch size 2000 - 87.87\n",
        "*   Batch size 5000 - 88.03\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Pjpe-GgptX",
        "outputId": "52486e8e-47e5-4f48-823e-a65cf9b4267c"
      },
      "source": [
        "size = 2000\n",
        "start = 0\n",
        "end = min(size,len(test_untagged) - start)\n",
        "accuracy = []\n",
        "for k in range(len(test_untagged)//size + 1):\n",
        "  res = []\n",
        "  pred_set = viterbi(test_untagged[start:end], unique_tags, train_set)\n",
        "  for i, j in zip(pred_set, test_set[start:end]):\n",
        "    if i == j: res.append(i) \n",
        "  accuracy.append((len(res)/len(pred_set))*100)\n",
        "  start = start + size\n",
        "  end = start + min(size,len(test_untagged) - start)\n",
        "  print(\"Accuracy for batch no.\", k+1, \":\", round(accuracy[k],2))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for batch no. 1 : 87.75\n",
            "Accuracy for batch no. 2 : 87.25\n",
            "Accuracy for batch no. 3 : 87.2\n",
            "Accuracy for batch no. 4 : 87.8\n",
            "Accuracy for batch no. 5 : 87.3\n",
            "Accuracy for batch no. 6 : 88.1\n",
            "Accuracy for batch no. 7 : 86.85\n",
            "Accuracy for batch no. 8 : 88.15\n",
            "Accuracy for batch no. 9 : 89.65\n",
            "Accuracy for batch no. 10 : 87.35\n",
            "Accuracy for batch no. 11 : 89.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJdX7qFim_Ek"
      },
      "source": [
        "**Obtaining average accuracy of all batches**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bZFGKWY8NvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfe7c33-edb0-4b8d-c2ac-dd60bd73cc85"
      },
      "source": [
        "print('Accuracy using own HMM trainer: ',round(statistics.mean(accuracy),2))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using own HMM trainer:  87.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6jENe04nHO0"
      },
      "source": [
        "# Performing HMM on test set using NLTK pre-existing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkwnecCdPDF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c6a930-8f18-48eb-cf84-7ff8cb26e888"
      },
      "source": [
        "from nltk.tag import hmm\n",
        "\n",
        "tagger = nltk.HiddenMarkovModelTagger.train([train_set])\n",
        "tagger.tag(test_untagged)\n",
        "print(\"Accuracy using NLTK HMM trainer:\", round(tagger.evaluate([test_set])*100,2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using NLTK HMM trainer: 92.05\n"
          ]
        }
      ]
    }
  ]
}
